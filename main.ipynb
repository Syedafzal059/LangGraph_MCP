{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e57799b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a41ed3",
   "metadata": {},
   "source": [
    "#can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61153f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create server parameters for stdio connection\n",
    "from mcp import ClientSession, StdioServerParameters \n",
    "from mcp.client.sse import sse_client\n",
    "from langchain_mcp_adapters.prompts import load_mcp_prompt\n",
    "from langchain_mcp_adapters.resources import load_mcp_resources\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your math_server.py file\n",
    "    args=[r\"C:\\Users\\Afzal\\Desktop\\mcp\\langraph_mcp\\poject00\\LangGraph_MCP\\mcp_server.py\"],\n",
    ")\n",
    "\n",
    "async with sse_client(url=\"http://127.0.0.1:8001/sse\") as streams:\n",
    "    async with ClientSession(*streams) as session:\n",
    "        # Initialize the connection\n",
    "        await session.initialize()\n",
    "\n",
    "        # Get tools\n",
    "        tools = await load_mcp_tools(session)\n",
    "                # 2) wrap your resources (including dynamic ones) as tools\n",
    "        resource_uris = [\"resource://some_static_resource\", \"greeting://{name}\"]\n",
    "        resource_tools = await load_mcp_resources(session, resource_uris)\n",
    "        # resources = await load_mcp_resources(session)\n",
    "        # #prompt = await load_mcp_prompt(session)\n",
    "        all_tools = tools + resource_tools\n",
    "\n",
    "        # Create and run the agent\n",
    "        agent = create_react_agent(model= model, tools=tools)\n",
    "        agent_response = await agent.ainvoke({\"messages\": \"\"\"First compute (3 + 5) × 12.  \"\"\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5bd2b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "First compute (3 + 5) × 12.  \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_fX6q9mw8g6DK40ZdPPUkI4lu)\n",
      " Call ID: call_fX6q9mw8g6DK40ZdPPUkI4lu\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "  multiply (call_7K3t1f4KpVwkRgN0WMl3kybm)\n",
      " Call ID: call_7K3t1f4KpVwkRgN0WMl3kybm\n",
      "  Args:\n",
      "    a: 8\n",
      "    b: 12\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "96\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of \\( (3 + 5) \\times 12 \\) is 96.\n"
     ]
    }
   ],
   "source": [
    "for m in agent_response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f284bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's (3 + 5) x 12? and what is the weather in nyc?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_lm4WJoiMirkd5eUDmSypSND9)\n",
      " Call ID: call_lm4WJoiMirkd5eUDmSypSND9\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "  get_current_weather (call_VF1nmlwicvKLnujC3h250BYP)\n",
      " Call ID: call_VF1nmlwicvKLnujC3h250BYP\n",
      "  Args:\n",
      "    location: New York City\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_current_weather\n",
      "\n",
      "{\n",
      "  \"location\": \"New York City\",\n",
      "  \"temperature_c\": 25,\n",
      "  \"condition\": \"Sunny\",\n",
      "  \"humidity_pct\": 40\n",
      "}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_ejjdodZbw3CmCf6yuwDq8AfY)\n",
      " Call ID: call_ejjdodZbw3CmCf6yuwDq8AfY\n",
      "  Args:\n",
      "    a: 8\n",
      "    b: 12\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "96\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of \\((3 + 5) \\times 12\\) is 96.\n",
      "\n",
      "The current weather in New York City is 25°C and sunny with a humidity of 40%.\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "        {\n",
    "            \"math\":{\n",
    "                \"url\": \"http://localhost:8001/sse\",\n",
    "                \"transport\": \"sse\",\n",
    "            },\n",
    "            \"weather\": {\n",
    "                \"url\": \"http://localhost:8002/sse\",\n",
    "                \"transport\": \"sse\",\n",
    "            },\n",
    "        }) as client:\n",
    "    tools = client.get_tools()    \n",
    "    agent = create_react_agent(model=model, tools=client.get_tools())\n",
    "    math_wheather_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12? and what is the weather in nyc?\"})\n",
    "\n",
    "\n",
    "for m in math_wheather_response[\"messages\"]:\n",
    "    m.pretty_print(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb5405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5723274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
